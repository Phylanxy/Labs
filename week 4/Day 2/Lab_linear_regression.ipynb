{
 "cells": [
  {
   "cell_type": "raw",
   "source": [
    "##%%\n",
    " import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "pd.options.display.max_rows = 50"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": ""
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"Data_Marketing_Customer_Analysis_Round3.csv\")\n",
    "# create dataframes with numerical...\n",
    "df_num = df[df.select_dtypes(include=[np.number]).columns].drop(\"total_claim_amount\", axis=1)\n",
    "# ...and categorical data only\n",
    "df_cat = df[df.select_dtypes(include=[object]).columns].drop(\"effective_to_date\", axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Data Exploration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# use pairplot to find correclated features\n",
    "sns.pairplot(df_num)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the most correlated features against each otherS\n",
    "plt.scatter(x=df_num[\"monthly_premium_auto\"], y=df_num[\"customer_lifetime_value\"], c=\"r\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# determine correlation matrix and plot correlation heatmap\n",
    "corr = df_num.corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True # trick to filter out the upper-right triangle, which is redundant due to symmetry\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(figsize=(16, 14))\n",
    "    ax = sns.heatmap(corr, mask=mask,cmap='coolwarm', vmin=-1,vmax=1,annot=True, square=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print(df_num.columns)\n",
    "# kick out any highly correlated features\n",
    "CORR_THRESH = 0.80\n",
    "corr_matrix = df_num.corr().abs()\n",
    "upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape),k=1).astype(bool))\n",
    "corrd_cols = [column for column in upper_triangle.columns if any(upper_triangle[column] > CORR_THRESH)]\n",
    "df_num.drop(corrd_cols,axis=1,inplace=True)\n",
    "#print(df_num.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot histplots of the numerical data\n",
    "df_num.hist(figsize=(11,12))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# monthly premium auto is scewed to the left\n",
    "#sns.histplot(df_num[\"income\"], kde=1)\n",
    "sns.histplot(df_num[\"monthly_premium_auto\"], kde=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# one-hot encode the categorical features\n",
    "cols_to_dummify = df_cat.columns\n",
    "df_dums = pd.DataFrame()\n",
    "for i, col in enumerate(cols_to_dummify):\n",
    "    df_dummies = pd.get_dummies(df_cat[col], drop_first=1)\n",
    "    # concatenate the original dataframe with the dummy variables\n",
    "    df_dums = pd.concat([df_dums, df_dummies], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. X-y split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.stats import zscore"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# filter the dataframe to remove the outliers\n",
    "def remove_outliers(num_df):\n",
    "    z = num_df.apply(zscore)\n",
    "    threshold = 3\n",
    "    num_df = num_df[(z < threshold).all(axis=1)]\n",
    "    return num_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the data with dummies and ordinally encoded categorical data and then load the numerical data\n",
    "# define numerical and categorical Xs and target feature y\n",
    "categoricalX = pd.read_csv(\"dum_df.csv\")\n",
    "numericalX = pd.read_csv(\"num_df.csv\").drop(\"total_claim_amount\", axis=1)\n",
    "\n",
    "X = pd.concat([categoricalX.iloc[remove_outliers(numericalX).index], remove_outliers(numericalX[numericalX.columns])], axis=1)\n",
    "y = df.iloc[remove_outliers(numericalX).index][\"total_claim_amount\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X.isna().any()\n",
    "# no need to drop anything"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Test - train split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RAND_STATE = 34 # for reproducible shuffling\n",
    "TT_RATIO = 0.3 # test/train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test-train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TT_RATIO, random_state=RAND_STATE)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "X_train.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Standardize data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# apply the StandardScaler to scale the distributions\n",
    "ss = StandardScaler()\n",
    "monthly_premium_transformed = ss.fit_transform(numericalX[\"monthly_premium_auto\"].to_numpy().reshape(-1,1))\n",
    "\n",
    "# original distribution\n",
    "sns.displot(numericalX[\"monthly_premium_auto\"], kde=1)\n",
    "# normalized distribution done with StandardScaler\n",
    "sns.displot(monthly_premium_transformed, kde=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# apply the PowerTransformer to scale the distributions\n",
    "pt = PowerTransformer()\n",
    "monthly_premium_transformed = pt.fit_transform(df_num['monthly_premium_auto'].to_numpy().reshape(-1,1))\n",
    "\n",
    "# original distribution\n",
    "sns.displot(numericalX[\"monthly_premium_auto\"], kde=1)\n",
    "# normalized and normally transformed distribution done with PowerTransform\n",
    "sns.displot(monthly_premium_transformed, kde=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"the parameters used to transform monthly_premium_transformed (pt) are\", pt.get_params(), \"\\nlambdas:\" , pt.lambdas_)\n",
    "# parameter used in the power transformation\n",
    "\n",
    "print(\"the parameters used to transform monthly_premium_transformed (ss) are\", ss.get_params())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ss = ColumnTransformer([(\"ss\", ss, list(numericalX.columns))],\n",
    "                        remainder='drop',verbose_feature_names_out=True,verbose=True).fit(X_train)\n",
    "X_train_ss = pd.DataFrame(ss.fit_transform(X_train), columns=ss.get_feature_names_out())\n",
    "X_test_ss = pd.DataFrame(ss.fit_transform(X_test), columns=ss.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# using the ColumnTransformer to transform the numerical columns with the PowerTransformer\n",
    "ct = ColumnTransformer([(\"pt\", pt, list(numericalX.columns))],\n",
    "                        remainder='drop',verbose_feature_names_out=True,verbose=True).fit(X_train)\n",
    "X_train_ct = pd.DataFrame(ct.transform(X_train),columns=ct.get_feature_names_out())\n",
    "X_test_ct = pd.DataFrame(ct.transform(X_test),columns=ct.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test_ss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Apply linear regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1 OLS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_const_ss = sm.add_constant(X_train_ss.to_numpy()) # adding a constant\n",
    "\n",
    "model_ss = sm.OLS(y_train, X_train_const_ss).fit()\n",
    "# predictions_train = model.predict(X_train_const_ct)\n",
    "\n",
    "X_test_const_ss = sm.add_constant(X_test_ss) # adding a constant\n",
    "predictions_test = model_ss.predict(X_test_const_ss)\n",
    "print_model = model_ss.summary()\n",
    "print(print_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_const_ct = sm.add_constant(X_train_ct.to_numpy()) # adding a constant\n",
    "\n",
    "model_ct = sm.OLS(y_train, X_train_const_ct).fit()\n",
    "# predictions_train = model.predict(X_train_const_ct)\n",
    "\n",
    "X_test_const_ct = sm.add_constant(X_test_ct) # adding a constant\n",
    "predictions_test = model_ct.predict(X_test_const_ct)\n",
    "print_model = model_ct.summary()\n",
    "print(print_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 SciKit Learn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# standard scaled train set\n",
    "model_ss=LinearRegression()    # model\n",
    "model_ss.fit(X_train_ss, y_train)   # model train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# power transformed train set\n",
    "model_ct=LinearRegression()    # model\n",
    "model_ct.fit(X_train_ct, y_train)   # model train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Model interpretation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(model_ss.coef_, \"\\n\", model_ct.coef_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(model_ss.intercept_, model_ct.intercept_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# standard scaler data\n",
    "y_pred_ss = pd.DataFrame(model_ss.predict(X_test_ct),columns = ['target_d'] )      # model prediction\n",
    "y_pred_train_ss = pd.DataFrame(model_ss.predict(X_train_ct),columns = ['target_d'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# power transformer data\n",
    "y_pred_ct = pd.DataFrame(model_ct.predict(X_test_ct),columns = ['target_d'] )      # model prediction\n",
    "y_pred_train_ct = pd.DataFrame(model_ct.predict(X_train_ct),columns = ['target_d'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(y_pred_ss, y_pred_ct)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(y_pred_train_ss, y_pred_train_ct)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_test = y_test.to_numpy().reshape(-1,1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# PLOTS FOR POWER TRANSFORMED DATA\n",
    "# Make an scatter plot y_pred vs y\n",
    "# What kind of plot you will get if all the predictions are ok?\n",
    "# A stright line\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(14,4))\n",
    "ax[0].plot(y_pred_ct, y_test, 'o')\n",
    "ax[0].set_xlabel(\"y_test\")\n",
    "ax[0].set_ylabel(\"y_pred\")\n",
    "ax[0].set_title(\"Test Set - Predicted vs real\")\n",
    "\n",
    "# Get a histogram of the residuals ie: y - y_pred.  Homoscedasticity\n",
    "# It resembles a normal distribution?\n",
    "ax[1].hist(y_test - y_pred_ct)\n",
    "ax[1].set_xlabel(\"Test y - y_pred\")\n",
    "ax[1].set_title(\"Test Set Residual histogram\")\n",
    "\n",
    "ax[2].plot(y_pred_ct,y_pred_ct.to_numpy() - y_test,\"o\")\n",
    "ax[2].set_xlabel(\"predicted\")\n",
    "ax[2].set_ylabel(\"residuals\")\n",
    "ax[2].set_title(\"Residuals by Predicted\")\n",
    "ax[2].plot(y_pred_ct,np.zeros(len(y_pred_ct)),linestyle='dashed')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# more fancy with seaborn\n",
    "yp_ = y_pred_ct\n",
    "yt_ = y_test\n",
    "sns.regplot(x=yp_,y=yt_,scatter_kws={\"color\": \"red\"}, line_kws={\"color\": \"black\"})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## checking Mean squared error for power transformed data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(mse(y_test,y_pred_ct))\n",
    "print(mae(y_test,y_pred_ct))\n",
    "# prediction on the train set\n",
    "print(mse(y_train,y_pred_train_ct))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## checking Mean squared error for standard scaler transformed data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(mse(y_test,y_pred_ss))\n",
    "print(mae(y_test,y_pred_ss))\n",
    "# prediction on the train set\n",
    "print(mse(y_train,y_pred_train_ss))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## and now the root of mean squares error"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
