{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "pd.options.display.max_rows = 50"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. X-y split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from scipy.stats import zscore"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# filter the dataframe to remove the outliers\n",
    "def remove_outliers(num_df):\n",
    "    z = num_df.apply(zscore)\n",
    "    threshold = 3\n",
    "    num_df = num_df[(z < threshold).all(axis=1)]\n",
    "    return num_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# load the data with dummies and ordinally encoded categorical data and then load the numerical data\n",
    "# define numerical and categorical Xs and target feature y\n",
    "\n",
    "X = pd.read_csv(\"Data_Marketing_Customer_Analysis_Round3.csv\")\n",
    "categoricalX = X.select_dtypes(object).drop(\"effective_to_date\",axis=1)\n",
    "\n",
    "categoricalX = pd.read_csv(\"dum_df.csv\")\n",
    "\n",
    "numericalX = pd.read_csv(\"num_df.csv\")\n",
    "y = numericalX[\"total_claim_amount\"]\n",
    "numericalX = numericalX.drop(\"total_claim_amount\", axis=1)\n",
    "\n",
    "X = pd.concat([categoricalX, numericalX], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Test - train split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "RAND_STATE = 34 # for reproducible shuffling\n",
    "TT_RATIO = 0.3 # test/train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "       coverage  education  vehicle_size  east  north west  west region  yes  \\\n2705          0          1             1     0           0            0    0   \n2209          0          1             1     0           0            0    0   \n4004          1          1             1     0           0            1    0   \n1898          0          1             1     1           0            0    0   \n10016         1          1             1     0           0            1    0   \n3098          0          1             0     0           0            1    0   \n1327          1          0             1     0           0            1    0   \n7903          1          1             1     1           0            0    0   \n7108          0          0             1     0           1            0    0   \n5142          0          0             1     0           0            1    1   \n\n       jan  employed  medical leave  ...  sports car  suv  two-door car  \\\n2705     1         1              0  ...           0    0             0   \n2209     0         0              0  ...           0    0             0   \n4004     1         1              0  ...           0    0             0   \n1898     1         0              0  ...           0    0             0   \n10016    1         1              0  ...           0    0             1   \n3098     1         1              0  ...           0    0             1   \n1327     0         1              0  ...           0    0             0   \n7903     1         1              0  ...           0    1             0   \n7108     1         1              0  ...           0    1             0   \n5142     1         1              0  ...           0    0             0   \n\n       customer_lifetime_value  income  monthly_premium_auto  \\\n2705                      4786   45515                    61   \n2209                     22445   80340                    71   \n4004                      6412   58776                    83   \n1898                      2254   48978                    65   \n10016                     7427   28848                    96   \n3098                      7579   33906                    64   \n1327                      3399   28928                    87   \n7903                     10990   44552                   137   \n7108                     12375   78441                   103   \n5142                      5639   73168                    70   \n\n       months_since_last_claim  months_since_policy_inception  \\\n2705                        10                             33   \n2209                        32                             35   \n4004                        20                             50   \n1898                         7                             95   \n10016                       22                             54   \n3098                        25                             49   \n1327                        23                              7   \n7903                         7                             42   \n7108                         6                             73   \n5142                        21                             50   \n\n       number_of_open_complaints  number_of_policies  \n2705                           0                   9  \n2209                           0                   2  \n4004                           2                   4  \n1898                           0                   1  \n10016                          0                   7  \n3098                           0                   2  \n1327                           1                   1  \n7903                           0                   3  \n7108                           0                   2  \n5142                           0                   3  \n\n[10 rows x 45 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>coverage</th>\n      <th>education</th>\n      <th>vehicle_size</th>\n      <th>east</th>\n      <th>north west</th>\n      <th>west region</th>\n      <th>yes</th>\n      <th>jan</th>\n      <th>employed</th>\n      <th>medical leave</th>\n      <th>...</th>\n      <th>sports car</th>\n      <th>suv</th>\n      <th>two-door car</th>\n      <th>customer_lifetime_value</th>\n      <th>income</th>\n      <th>monthly_premium_auto</th>\n      <th>months_since_last_claim</th>\n      <th>months_since_policy_inception</th>\n      <th>number_of_open_complaints</th>\n      <th>number_of_policies</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2705</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4786</td>\n      <td>45515</td>\n      <td>61</td>\n      <td>10</td>\n      <td>33</td>\n      <td>0</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2209</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>22445</td>\n      <td>80340</td>\n      <td>71</td>\n      <td>32</td>\n      <td>35</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4004</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6412</td>\n      <td>58776</td>\n      <td>83</td>\n      <td>20</td>\n      <td>50</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1898</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2254</td>\n      <td>48978</td>\n      <td>65</td>\n      <td>7</td>\n      <td>95</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10016</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7427</td>\n      <td>28848</td>\n      <td>96</td>\n      <td>22</td>\n      <td>54</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3098</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7579</td>\n      <td>33906</td>\n      <td>64</td>\n      <td>25</td>\n      <td>49</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1327</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3399</td>\n      <td>28928</td>\n      <td>87</td>\n      <td>23</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7903</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>10990</td>\n      <td>44552</td>\n      <td>137</td>\n      <td>7</td>\n      <td>42</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7108</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>12375</td>\n      <td>78441</td>\n      <td>103</td>\n      <td>6</td>\n      <td>73</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5142</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5639</td>\n      <td>73168</td>\n      <td>70</td>\n      <td>21</td>\n      <td>50</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 45 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test-train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TT_RATIO, random_state=RAND_STATE)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "X_train.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Standardize data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ColumnTransformer] ............ (1 of 1) Processing pt, total=   1.2s\n"
     ]
    }
   ],
   "source": [
    "# using the ColumnTransformer to transform the numerical columns with the PowerTransformer\n",
    "pt = PowerTransformer()\n",
    "\n",
    "ct = ColumnTransformer([(\"pt\", pt, list(X.columns))],\n",
    "                        remainder='drop',verbose_feature_names_out=True,verbose=True).fit(X_train)\n",
    "X_train_ct = pd.DataFrame(ct.transform(X_train),columns=ct.get_feature_names_out())\n",
    "X_test_ct = pd.DataFrame(ct.transform(X_test),columns=ct.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "      pt__coverage  pt__education  pt__vehicle_size  pt__east  pt__north west  \\\n0        -0.799409       0.332813          0.150382 -0.314388       -0.630651   \n1        -0.799409       0.332813          0.150382 -0.314388       -0.630651   \n2         1.145812       0.332813          0.150382 -0.314388       -0.630651   \n3        -0.799409       0.332813          0.150382  3.180784       -0.630651   \n4         1.145812       0.332813          0.150382 -0.314388       -0.630651   \n...            ...            ...               ...       ...             ...   \n7477      1.145812       0.332813         -1.685971 -0.314388        1.585663   \n7478      1.545906       0.332813         -1.685971 -0.314388       -0.630651   \n7479     -0.799409      -1.393362          0.150382 -0.314388       -0.630651   \n7480      1.145812       0.332813          0.150382 -0.314388       -0.630651   \n7481     -0.799409      -1.393362          2.062844 -0.314388       -0.630651   \n\n      pt__west region   pt__yes   pt__jan  pt__employed  pt__medical leave  \\\n0           -0.723975 -0.383659  0.925265      0.775536          -0.216501   \n1           -0.723975 -0.383659 -1.080772     -1.289431          -0.216501   \n2            1.381264 -0.383659  0.925265      0.775536          -0.216501   \n3           -0.723975 -0.383659  0.925265     -1.289431          -0.216501   \n4            1.381264 -0.383659  0.925265      0.775536          -0.216501   \n...               ...       ...       ...           ...                ...   \n7477        -0.723975 -0.383659 -1.080772     -1.289431          -0.216501   \n7478         1.381264 -0.383659  0.925265     -1.289431          -0.216501   \n7479         1.381264 -0.383659 -1.080772      0.775536          -0.216501   \n7480        -0.723975 -0.383659  0.925265      0.775536          -0.216501   \n7481         1.381264 -0.383659  0.925265     -1.289431          -0.216501   \n\n      ...  pt__sports car   pt__suv  pt__two-door car  \\\n0     ...       -0.233868 -0.495527         -0.505757   \n1     ...       -0.233868 -0.495527         -0.505757   \n2     ...       -0.233868 -0.495527         -0.505757   \n3     ...       -0.233868 -0.495527         -0.505757   \n4     ...       -0.233868 -0.495527          1.977233   \n...   ...             ...       ...               ...   \n7477  ...       -0.233868 -0.495527         -0.505757   \n7478  ...       -0.233868 -0.495527          1.977233   \n7479  ...       -0.233868 -0.495527         -0.505757   \n7480  ...       -0.233868 -0.495527         -0.505757   \n7481  ...       -0.233868  2.018054         -0.505757   \n\n      pt__customer_lifetime_value  pt__income  pt__monthly_premium_auto  \\\n0                       -0.340765   -0.143033                 -1.552039   \n1                        1.732220    1.108667                 -0.712384   \n2                        0.142838    0.372284                 -0.020814   \n3                       -1.841641   -0.002560                 -1.178270   \n4                        0.367618   -0.900458                  0.496901   \n...                           ...         ...                       ...   \n7477                     0.199678   -0.194957                  0.593059   \n7478                     0.928730   -0.082468                  0.938141   \n7479                    -1.511516    1.656755                 -1.178270   \n7480                    -0.980688   -1.203165                  0.200536   \n7481                     0.557305    1.703047                  1.004347   \n\n      pt__months_since_last_claim  pt__months_since_policy_inception  \\\n0                       -0.350352                          -0.428756   \n1                        1.463437                          -0.354308   \n2                        0.582646                           0.170412   \n3                       -0.700972                           1.525083   \n4                        0.742711                           0.302193   \n...                           ...                                ...   \n7477                     0.240451                           0.650895   \n7478                     0.971550                           0.773350   \n7479                    -0.040648                          -0.428756   \n7480                    -0.461825                          -1.644616   \n7481                    -0.040648                          -0.067825   \n\n      pt__number_of_open_complaints  pt__number_of_policies  \n0                         -0.502522                1.660057  \n1                         -0.502522               -0.063268  \n2                          2.032405                0.875803  \n3                         -0.502522               -1.143833  \n4                         -0.502522                1.454127  \n...                             ...                     ...  \n7477                       2.032405                0.513168  \n7478                      -0.502522               -0.063268  \n7479                      -0.502522               -1.143833  \n7480                       2.032405               -1.143833  \n7481                      -0.502522                0.875803  \n\n[7482 rows x 45 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pt__coverage</th>\n      <th>pt__education</th>\n      <th>pt__vehicle_size</th>\n      <th>pt__east</th>\n      <th>pt__north west</th>\n      <th>pt__west region</th>\n      <th>pt__yes</th>\n      <th>pt__jan</th>\n      <th>pt__employed</th>\n      <th>pt__medical leave</th>\n      <th>...</th>\n      <th>pt__sports car</th>\n      <th>pt__suv</th>\n      <th>pt__two-door car</th>\n      <th>pt__customer_lifetime_value</th>\n      <th>pt__income</th>\n      <th>pt__monthly_premium_auto</th>\n      <th>pt__months_since_last_claim</th>\n      <th>pt__months_since_policy_inception</th>\n      <th>pt__number_of_open_complaints</th>\n      <th>pt__number_of_policies</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.799409</td>\n      <td>0.332813</td>\n      <td>0.150382</td>\n      <td>-0.314388</td>\n      <td>-0.630651</td>\n      <td>-0.723975</td>\n      <td>-0.383659</td>\n      <td>0.925265</td>\n      <td>0.775536</td>\n      <td>-0.216501</td>\n      <td>...</td>\n      <td>-0.233868</td>\n      <td>-0.495527</td>\n      <td>-0.505757</td>\n      <td>-0.340765</td>\n      <td>-0.143033</td>\n      <td>-1.552039</td>\n      <td>-0.350352</td>\n      <td>-0.428756</td>\n      <td>-0.502522</td>\n      <td>1.660057</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.799409</td>\n      <td>0.332813</td>\n      <td>0.150382</td>\n      <td>-0.314388</td>\n      <td>-0.630651</td>\n      <td>-0.723975</td>\n      <td>-0.383659</td>\n      <td>-1.080772</td>\n      <td>-1.289431</td>\n      <td>-0.216501</td>\n      <td>...</td>\n      <td>-0.233868</td>\n      <td>-0.495527</td>\n      <td>-0.505757</td>\n      <td>1.732220</td>\n      <td>1.108667</td>\n      <td>-0.712384</td>\n      <td>1.463437</td>\n      <td>-0.354308</td>\n      <td>-0.502522</td>\n      <td>-0.063268</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.145812</td>\n      <td>0.332813</td>\n      <td>0.150382</td>\n      <td>-0.314388</td>\n      <td>-0.630651</td>\n      <td>1.381264</td>\n      <td>-0.383659</td>\n      <td>0.925265</td>\n      <td>0.775536</td>\n      <td>-0.216501</td>\n      <td>...</td>\n      <td>-0.233868</td>\n      <td>-0.495527</td>\n      <td>-0.505757</td>\n      <td>0.142838</td>\n      <td>0.372284</td>\n      <td>-0.020814</td>\n      <td>0.582646</td>\n      <td>0.170412</td>\n      <td>2.032405</td>\n      <td>0.875803</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.799409</td>\n      <td>0.332813</td>\n      <td>0.150382</td>\n      <td>3.180784</td>\n      <td>-0.630651</td>\n      <td>-0.723975</td>\n      <td>-0.383659</td>\n      <td>0.925265</td>\n      <td>-1.289431</td>\n      <td>-0.216501</td>\n      <td>...</td>\n      <td>-0.233868</td>\n      <td>-0.495527</td>\n      <td>-0.505757</td>\n      <td>-1.841641</td>\n      <td>-0.002560</td>\n      <td>-1.178270</td>\n      <td>-0.700972</td>\n      <td>1.525083</td>\n      <td>-0.502522</td>\n      <td>-1.143833</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.145812</td>\n      <td>0.332813</td>\n      <td>0.150382</td>\n      <td>-0.314388</td>\n      <td>-0.630651</td>\n      <td>1.381264</td>\n      <td>-0.383659</td>\n      <td>0.925265</td>\n      <td>0.775536</td>\n      <td>-0.216501</td>\n      <td>...</td>\n      <td>-0.233868</td>\n      <td>-0.495527</td>\n      <td>1.977233</td>\n      <td>0.367618</td>\n      <td>-0.900458</td>\n      <td>0.496901</td>\n      <td>0.742711</td>\n      <td>0.302193</td>\n      <td>-0.502522</td>\n      <td>1.454127</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7477</th>\n      <td>1.145812</td>\n      <td>0.332813</td>\n      <td>-1.685971</td>\n      <td>-0.314388</td>\n      <td>1.585663</td>\n      <td>-0.723975</td>\n      <td>-0.383659</td>\n      <td>-1.080772</td>\n      <td>-1.289431</td>\n      <td>-0.216501</td>\n      <td>...</td>\n      <td>-0.233868</td>\n      <td>-0.495527</td>\n      <td>-0.505757</td>\n      <td>0.199678</td>\n      <td>-0.194957</td>\n      <td>0.593059</td>\n      <td>0.240451</td>\n      <td>0.650895</td>\n      <td>2.032405</td>\n      <td>0.513168</td>\n    </tr>\n    <tr>\n      <th>7478</th>\n      <td>1.545906</td>\n      <td>0.332813</td>\n      <td>-1.685971</td>\n      <td>-0.314388</td>\n      <td>-0.630651</td>\n      <td>1.381264</td>\n      <td>-0.383659</td>\n      <td>0.925265</td>\n      <td>-1.289431</td>\n      <td>-0.216501</td>\n      <td>...</td>\n      <td>-0.233868</td>\n      <td>-0.495527</td>\n      <td>1.977233</td>\n      <td>0.928730</td>\n      <td>-0.082468</td>\n      <td>0.938141</td>\n      <td>0.971550</td>\n      <td>0.773350</td>\n      <td>-0.502522</td>\n      <td>-0.063268</td>\n    </tr>\n    <tr>\n      <th>7479</th>\n      <td>-0.799409</td>\n      <td>-1.393362</td>\n      <td>0.150382</td>\n      <td>-0.314388</td>\n      <td>-0.630651</td>\n      <td>1.381264</td>\n      <td>-0.383659</td>\n      <td>-1.080772</td>\n      <td>0.775536</td>\n      <td>-0.216501</td>\n      <td>...</td>\n      <td>-0.233868</td>\n      <td>-0.495527</td>\n      <td>-0.505757</td>\n      <td>-1.511516</td>\n      <td>1.656755</td>\n      <td>-1.178270</td>\n      <td>-0.040648</td>\n      <td>-0.428756</td>\n      <td>-0.502522</td>\n      <td>-1.143833</td>\n    </tr>\n    <tr>\n      <th>7480</th>\n      <td>1.145812</td>\n      <td>0.332813</td>\n      <td>0.150382</td>\n      <td>-0.314388</td>\n      <td>-0.630651</td>\n      <td>-0.723975</td>\n      <td>-0.383659</td>\n      <td>0.925265</td>\n      <td>0.775536</td>\n      <td>-0.216501</td>\n      <td>...</td>\n      <td>-0.233868</td>\n      <td>-0.495527</td>\n      <td>-0.505757</td>\n      <td>-0.980688</td>\n      <td>-1.203165</td>\n      <td>0.200536</td>\n      <td>-0.461825</td>\n      <td>-1.644616</td>\n      <td>2.032405</td>\n      <td>-1.143833</td>\n    </tr>\n    <tr>\n      <th>7481</th>\n      <td>-0.799409</td>\n      <td>-1.393362</td>\n      <td>2.062844</td>\n      <td>-0.314388</td>\n      <td>-0.630651</td>\n      <td>1.381264</td>\n      <td>-0.383659</td>\n      <td>0.925265</td>\n      <td>-1.289431</td>\n      <td>-0.216501</td>\n      <td>...</td>\n      <td>-0.233868</td>\n      <td>2.018054</td>\n      <td>-0.505757</td>\n      <td>0.557305</td>\n      <td>1.703047</td>\n      <td>1.004347</td>\n      <td>-0.040648</td>\n      <td>-0.067825</td>\n      <td>-0.502522</td>\n      <td>0.875803</td>\n    </tr>\n  </tbody>\n</table>\n<p>7482 rows × 45 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ct"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Apply linear regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1 OLS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:     total_claim_amount   R-squared:                       0.739\n",
      "Model:                            OLS   Adj. R-squared:                  0.738\n",
      "Method:                 Least Squares   F-statistic:                     491.0\n",
      "Date:                Thu, 02 Feb 2023   Prob (F-statistic):               0.00\n",
      "Time:                        17:29:02   Log-Likelihood:                -48041.\n",
      "No. Observations:                7482   AIC:                         9.617e+04\n",
      "Df Residuals:                    7438   BIC:                         9.647e+04\n",
      "Df Model:                          43                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        435.8295      1.724    252.786      0.000     432.450     439.209\n",
      "x1            11.3590      2.784      4.081      0.000       5.902      16.815\n",
      "x2            -6.3935      1.760     -3.632      0.000      -9.844      -2.943\n",
      "x3            -0.9650      1.749     -0.552      0.581      -4.394       2.464\n",
      "x4             1.8639      1.895      0.983      0.325      -1.851       5.579\n",
      "x5             0.6617      2.071      0.319      0.749      -3.399       4.722\n",
      "x6             1.2673      2.089      0.607      0.544      -2.828       5.362\n",
      "x7            -6.9323      1.870     -3.706      0.000     -10.599      -3.266\n",
      "x8            -1.2738      1.730     -0.736      0.462      -4.665       2.117\n",
      "x9            -2.5434      4.405     -0.577      0.564     -11.179       6.093\n",
      "x10            3.0129      2.379      1.267      0.205      -1.650       7.676\n",
      "x11           -3.0937      2.235     -1.384      0.166      -7.475       1.288\n",
      "x12           34.9810      4.191      8.347      0.000      26.765      43.197\n",
      "x13            8.4826      1.743      4.866      0.000       5.065      11.900\n",
      "x14          184.5127      2.401     76.835      0.000     179.805     189.220\n",
      "x15           82.8738      2.161     38.345      0.000      78.637      87.111\n",
      "x16           -1.4766      2.528     -0.584      0.559      -6.431       3.478\n",
      "x17           28.6873      2.616     10.967      0.000      23.560      33.815\n",
      "x18           -0.9940      2.890     -0.344      0.731      -6.660       4.672\n",
      "x19            0.6772      1.232      0.549      0.583      -1.739       3.093\n",
      "x20           -2.4740      2.726     -0.907      0.364      -7.819       2.871\n",
      "x21           -0.1900      3.202     -0.059      0.953      -6.468       6.088\n",
      "x22            1.5545      1.621      0.959      0.338      -1.624       4.733\n",
      "x23           -1.2759      1.584     -0.805      0.421      -4.381       1.829\n",
      "x24           -0.8925      1.558     -0.573      0.567      -3.947       2.162\n",
      "x25            2.8316      1.637      1.729      0.084      -0.378       6.041\n",
      "x26           -1.3231      1.521     -0.870      0.384      -4.305       1.659\n",
      "x27            0.4694      1.543      0.304      0.761      -2.555       3.493\n",
      "x28            6.1244      2.025      3.024      0.003       2.155      10.094\n",
      "x29            1.5281      1.915      0.798      0.425      -2.225       5.281\n",
      "x30            1.8592      1.939      0.959      0.338      -1.941       5.659\n",
      "x31           -1.6409      1.948     -0.842      0.400      -5.459       2.178\n",
      "x32           -0.7177      1.933     -0.371      0.710      -4.507       3.072\n",
      "x33           -0.9676      1.917     -0.505      0.614      -4.725       2.790\n",
      "x34           60.5377      2.164     27.974      0.000      56.296      64.780\n",
      "x35           55.1766      2.182     25.289      0.000      50.900      59.454\n",
      "x36           10.3334      2.216      4.663      0.000       5.989      14.677\n",
      "x37           18.5390      2.985      6.210      0.000      12.687      24.391\n",
      "x38           -1.5307      1.826     -0.838      0.402      -5.110       2.049\n",
      "x39            7.8029      2.352      3.317      0.001       3.192      12.414\n",
      "x40           -5.7104      2.051     -2.784      0.005      -9.732      -1.689\n",
      "x41           97.9821      4.219     23.224      0.000      89.712     106.253\n",
      "x42            3.9465      1.732      2.279      0.023       0.551       7.342\n",
      "x43            0.7374      1.745      0.423      0.673      -2.684       4.159\n",
      "x44           -3.0418      1.739     -1.750      0.080      -6.450       0.366\n",
      "x45           -3.8044      2.075     -1.834      0.067      -7.871       0.262\n",
      "==============================================================================\n",
      "Omnibus:                     3845.438   Durbin-Watson:                   2.005\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            64468.719\n",
      "Skew:                           2.067   Prob(JB):                         0.00\n",
      "Kurtosis:                      16.774   Cond. No.                     5.04e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 8.58e-28. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "X_train_const_ct = sm.add_constant(X_train_ct.to_numpy()) # adding a constant\n",
    "\n",
    "model_ct = sm.OLS(y_train, X_train_const_ct).fit()\n",
    "# predictions_train = model.predict(X_train_const_ct)\n",
    "\n",
    "X_test_const_ct = sm.add_constant(X_test_ct) # adding a constant\n",
    "predictions_test = model_ct.predict(X_test_const_ct)\n",
    "print_model = model_ct.summary()\n",
    "print(print_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_ct' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_10764\\1298446790.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mfig\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0max\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msubplots\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mfigsize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m14\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0mfig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msuptitle\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Power Transformed Data\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m \u001B[0max\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_pred_ct\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'o'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m \u001B[0max\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset_xlabel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"y_test\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[0max\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset_ylabel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"y_pred\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'y_pred_ct' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1400x400 with 3 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOTS FOR POWER TRANSFORMED DATA\n",
    "# Make an scatter plot y_pred vs y\n",
    "# What kind of plot you will get if all the predictions are ok?\n",
    "# A stright line\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(14,4))\n",
    "fig.suptitle(\"Power Transformed Data\")\n",
    "ax[0].plot(y_pred_ct, y_test, 'o')\n",
    "ax[0].set_xlabel(\"y_test\")\n",
    "ax[0].set_ylabel(\"y_pred\")\n",
    "ax[0].set_title(\"Test Set - Predicted vs real\")\n",
    "\n",
    "# Get a histogram of the residuals ie: y - y_pred.  Homoscedasticity\n",
    "# It resembles a normal distribution?\n",
    "ax[1].hist(y_test - y_pred_ct)\n",
    "ax[1].set_xlabel(\"Test y - y_pred\")\n",
    "ax[1].set_title(\"Test Set Residual histogram\")\n",
    "\n",
    "ax[2].plot(y_pred_ct,y_pred_ct.to_numpy() - y_test,\"o\")\n",
    "ax[2].set_xlabel(\"predicted\")\n",
    "ax[2].set_ylabel(\"residuals\")\n",
    "ax[2].set_title(\"Residuals by Predicted\")\n",
    "ax[2].plot(y_pred_ct,np.zeros(len(y_pred_ct)),linestyle='dashed')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
