{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "dc5b0b44",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import statistics as st\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "2dae267e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# define a function to convert the columns of a df into all lower case\n",
    "def convert_cols_to_lower(df):\n",
    "    df.columns = [ i.lower() for i in df.columns ]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "87d2073f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# define a column list with the names for all the columns\n",
    "column_lst = sorted(['Customer', 'State', 'Gender', 'Education', 'Customer Lifetime Value',\n",
    "       'Income', 'Monthly Premium Auto', 'Number of Open Complaints',\n",
    "       'Policy Type', 'Vehicle Class', 'Total Claim Amount'])\n",
    "\n",
    "# define a function to read all three dataset into three files, assure the column names are the same and then concatenate them into one dataset\n",
    "def load_original_data():\n",
    "    file1 = pd.read_csv('Data/file1.csv')\n",
    "    file2 = pd.read_csv('Data/file2.csv')\n",
    "    file3 = pd.read_csv('Data/file3.csv')\n",
    "    \n",
    "    convert_cols_to_lower(file1)\n",
    "    convert_cols_to_lower(file2)\n",
    "    convert_cols_to_lower(file3)\n",
    "    \n",
    "    file1 = file1.sort_index(axis=1)\n",
    "    file2 = file2.sort_index(axis=1)\n",
    "    file3 = file3.sort_index(axis=1)\n",
    "    \n",
    "    file1.columns = column_lst\n",
    "    file2.columns = column_lst\n",
    "    # replace state by st in file3\n",
    "    file3.columns = file3.columns.str.replace(\"state\", \"st\")\n",
    "    file3.columns = column_lst\n",
    "    \n",
    "    df = pd.concat([file1, file2, file3], axis=0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "5af1807c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# load the full dataset, correctly concatenated and in the desired order\n",
    "full_dataset = load_original_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "id": "c5e0cc35",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# turn column names into lower and replace space by underscore\n",
    "full_dataset.columns = [ i for i in full_dataset.columns.str.replace(\" \",\"_\").str.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "ee8fbfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Customer column as it is basically an index\n",
    "full_dataset = full_dataset.drop(\"customer\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "aca5a10f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "full_dataset = full_dataset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "d7ffecfc",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# reset the index to match the amount of rows\n",
    "full_dataset = full_dataset.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "eb92fb50",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# remove \"%\" signs from Customer Lifetime Value where present and divide these values by 100 to account for unusually high values probably caused by wrong formatting and therefore multiplying by 100\n",
    "full_dataset[\"customer_lifetime_value\"] = (\n",
    "    full_dataset[\"customer_lifetime_value\"].apply(lambda x: float(x.replace(\"%\", \" \"))/100 if type(x) == str else x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "edb358f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# convert Customer Lifetime Value into integer by converting it to numeric and then truncating it (as requested in assignment task)\n",
    "full_dataset[\"customer_lifetime_value\"] = pd.to_numeric(full_dataset[\"customer_lifetime_value\"], errors = \"coerce\")\n",
    "# using lambda function to check for nans and if not nan apply truncate\n",
    "full_dataset[\"customer_lifetime_value\"] = full_dataset[\"customer_lifetime_value\"].apply(lambda x: math.trunc(x) if np.isnan(x) != True else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "fa9b039c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# function that checks if input is a string and splits it at \"/\" if it is\n",
    "# returning the 2nd element of the resulting list or returning x if it's not a string\n",
    "def split(x):\n",
    "    if isinstance(x, str):\n",
    "        return x.split(\"/\")[1]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "49b4c2f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# apply split() and convert to numbers\n",
    "full_dataset[\"number_of_open_complaints\"] = full_dataset[\"number_of_open_complaints\"].apply(lambda x: split(x))\n",
    "full_dataset[\"number_of_open_complaints\"] = pd.to_numeric(full_dataset[\"number_of_open_complaints\"], errors = \"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "36620816",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>customer_lifetime_value</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>monthly_premium_auto</th>\n",
       "      <th>number_of_open_complaints</th>\n",
       "      <th>policy_type</th>\n",
       "      <th>state</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>vehicle_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>1071</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  customer_lifetime_value education gender  income  \\\n",
       "1070   1071                        0       NaN    NaN     NaN   \n",
       "\n",
       "      monthly_premium_auto  number_of_open_complaints policy_type state  \\\n",
       "1070                   NaN                        NaN         NaN   NaN   \n",
       "\n",
       "      total_claim_amount vehicle_class  \n",
       "1070                 NaN           NaN  "
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for nans\n",
    "full_dataset.loc[full_dataset[\"number_of_open_complaints\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "f5f6b797",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# drop row 1071 that only contains nans\n",
    "full_dataset = full_dataset.drop([1071])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "df24276d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# function that checks if a given string is found in a list of possible descriptors of male and female and then replaces them for the same\n",
    "def clean_gender(string):\n",
    "    m_lst = ['M', 'Male']\n",
    "    f_lst = ['F', 'Femal', 'female']\n",
    "    if isinstance(string, str) and string in m_lst:\n",
    "        return \"male\"\n",
    "    elif isinstance(string, str) and string in f_lst:\n",
    "        return \"female\"\n",
    "    else:\n",
    "        return \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "id": "6665655b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# apply the map function to generate the \"gender\" column again and overwrite the old column with it\n",
    "full_dataset['gender'] = list(map(clean_gender, full_dataset['gender']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7903fe1d",
   "metadata": {},
   "source": [
    "## Day 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "id": "0a6e7dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 0s with np.nan\n",
    "full_dataset[\"income\"] = full_dataset[\"income\"].replace(to_replace=0, value=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "id": "f53754fd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# fill mean of column to elements with NaN\n",
    "full_dataset[\"income\"] = full_dataset[\"income\"].replace(to_replace=np.nan, value=full_dataset[\"income\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "id": "4c0144c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 0s with np.nan\n",
    "full_dataset[\"monthly_premium_auto\"] = full_dataset[\"monthly_premium_auto\"].replace(to_replace=0, value=np.nan)\n",
    "# fill mean of column to elements with NaN\n",
    "full_dataset[\"monthly_premium_auto\"] = (\n",
    "    full_dataset[\"monthly_premium_auto\"].replace(to_replace=np.nan, value=full_dataset[\"monthly_premium_auto\"].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "id": "8f87351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 0s with np.nan\n",
    "full_dataset[\"total_claim_amount\"] = full_dataset[\"total_claim_amount\"].replace(to_replace=0, value=np.nan)\n",
    "# fill mean of column to elements with NaN\n",
    "full_dataset[\"total_claim_amount\"] = (\n",
    "    full_dataset[\"total_claim_amount\"].replace(to_replace=np.nan, value=full_dataset[\"total_claim_amount\"].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e4c30e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Bucketing the data - Write a function to replace column \"State\" to different zones. California as West Region, Oregon as North West, and Washington as East, and Arizona and Nevada as Central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "61e84e06",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Washington', 'Arizona', 'Nevada', 'California', 'Oregon', 'Cali',\n",
       "       'AZ', 'WA', nan], dtype=object)"
      ]
     },
     "execution_count": 770,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for values in column \"state\"\n",
    "full_dataset[\"state\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "id": "222a9415",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "region_lst = ['California', 'Cali', 'Oregon', \"Washington\", 'WA', \"Arizona\", 'AZ', \"Nevada\"]\n",
    "def bucket(string, lst):\n",
    "    if string == (lst[0] or lst[1]):\n",
    "        return \"west_region\"\n",
    "    elif string == lst[2]:\n",
    "        return \"north_west\"\n",
    "    elif string == (lst[3] or lst[4]):\n",
    "        return \"east\"\n",
    "    elif string == (lst[5] or lst[6] or lst[7]):\n",
    "        return \"central\"\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "af44731d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "full_dataset[\"state\"] = full_dataset[\"state\"].apply(lambda x: bucket(x,region_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "3a323abd",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "full_dataset = full_dataset.drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "daea4d5f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "full_dataset[\"education\"] = full_dataset[\"education\"].str.lower()\n",
    "full_dataset[\"policy_type\"] = full_dataset[\"policy_type\"].str.lower()\n",
    "full_dataset[\"vehicle_class\"] = full_dataset[\"vehicle_class\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "20e8817e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "replace_dict = {\"luxury suv\": \"luxury vehicle\" , \"luxury car\" : \"luxury vehicle\"}\n",
    "full_dataset[\"vehicle_class\"] = full_dataset[\"vehicle_class\"].replace(replace_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "09f56f98",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# create index of all columns with numerical data\n",
    "numeric_cols = full_dataset.select_dtypes(include=[np.number]).columns\n",
    "# delete the ones that dont make any sense to remove the outliers from\n",
    "numeric_cols = numeric_cols.drop([\"number_of_open_complaints\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "020d5894",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# create a dataframe only containing numerical data, based on the index numeric_cols and then apply the zscore to filter out the outliers above a threshold of three with is comparable to the 1.5*IQR method\n",
    "numeric_data = full_dataset[numeric_cols]\n",
    "z = full_dataset[numeric_cols].apply(zscore)\n",
    "threshold = 3\n",
    "\n",
    "# filter the dataframe to remove the outliers\n",
    "full_dataset = full_dataset[(z < threshold).all(axis=1)]"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
